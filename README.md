# PredicciÃ³n de Abandono de Clientes (Customer Churn) â€” Proyecto de Machine Learning

## ğŸ“Œ DescripciÃ³n general del proyecto

Este proyecto aborda el problema de **predicciÃ³n de abandono de clientes (Customer Churn)** utilizando tÃ©cnicas de **Machine Learning supervisado**.  
El objetivo es construir un modelo **realista, interpretable y correctamente evaluado**, siguiendo buenas prÃ¡cticas de Ciencia de Datos aplicadas a datos reales.

El proyecto pone especial Ã©nfasis en:
- separaciÃ³n correcta de los datos
- mÃ©tricas adecuadas para datasets desbalanceados
- ajuste de threshold
- comparaciÃ³n honesta de modelos
- reproducibilidad y claridad del proceso

---

## ğŸ¯ Objetivo de negocio

El churn busca identificar clientes con alta probabilidad de abandonar un servicio.  
En este tipo de problemas, **no detectar un cliente que abandona (falso negativo)** suele ser mÃ¡s costoso que alertar a uno que no lo harÃ¡.

Por este motivo, se priorizan mÃ©tricas como **recall** y **F1-score**, en lugar de accuracy.

---

## ğŸ“Š Dataset

**Telco Customer Churn Dataset**

- Variable objetivo binaria: `Churn`
- Desbalance moderado de clases
- Variables numÃ©ricas y categÃ³ricas

CodificaciÃ³n del target:
```python
y = data['Churn'].map({'No': 0, 'Yes': 1})

#----------------------------------------------------

ğŸ”€ DivisiÃ³n de los datos

Se aplicÃ³ una divisiÃ³n estricta y correcta:

Entrenamiento (Train): 60%

ValidaciÃ³n (Validation): 20%

Test: 20%

Utilizando stratify para preservar la proporciÃ³n de clases.

ğŸ‘‰ El conjunto test se utilizÃ³ una sola vez, al final del proyecto.

#----------------------------------------------------

ğŸ”§ Preprocesamiento

Se implementÃ³ un pipeline estructurado con ColumnTransformer.

Variables numÃ©ricas

ImputaciÃ³n por mediana

RobustScaler

Variables categÃ³ricas

ImputaciÃ³n por valor mÃ¡s frecuente

One-Hot Encoding (handle_unknown='ignore')

#----------------------------------------------------

ğŸ¤– Modelos evaluados
RegresiÃ³n LogÃ­stica (Modelo final)

Entrenamiento baseline

OptimizaciÃ³n de hiperparÃ¡metros con GridSearchCV

MÃ©trica de optimizaciÃ³n: Average Precision (PR-AUC)

Ajuste manual del threshold usando validation

Random Forest (Modelo de comparaciÃ³n)

Evaluado como alternativa no lineal

Comportamiento excesivamente conservador

F1-score inestable tras el ajuste de threshold

Finalmente descartado

#----------------------------------------------------

âš™ï¸ Ajuste de threshold

Dado que el modelo produce probabilidades, el threshold por defecto (0.5) no resultÃ³ Ã³ptimo.

Se evaluaron distintos valores sobre el conjunto de validaciÃ³n y se seleccionÃ³:

Threshold final: 0.4

Este valor ofreciÃ³ un mejor equilibrio entre recall y F1-score.

#----------------------------------------------------

ğŸ§ª Resultados finales en Test

El modelo final de RegresiÃ³n LogÃ­stica fue reentrenado utilizando train + validation, y evaluado una sola vez sobre test.

Resultados en test:

F1-score: 0.60

Recall: 0.64

La leve caÃ­da respecto a validation es esperable y confirma una buena capacidad de generalizaciÃ³n, sin data leakage.

#----------------------------------------------------

ğŸ“ˆ VisualizaciÃ³n con PCA (Interpretabilidad)

Se aplicÃ³ PCA Ãºnicamente con fines exploratorios y de visualizaciÃ³n, no para entrenar el modelo.

La proyecciÃ³n a 2 componentes muestra un alto solapamiento entre clientes que abandonan y los que no, lo que evidencia:

la complejidad del problema

la ausencia de una separaciÃ³n clara en baja dimensiÃ³n

Este grÃ¡fico ayuda a interpretar por quÃ© mÃ©tricas moderadas son esperables en un problema real de churn.

#----------------------------------------------------
ğŸ§  Conclusiones principales

La RegresiÃ³n LogÃ­stica demostrÃ³ ser un modelo sÃ³lido e interpretable

El ajuste de threshold tuvo un impacto significativo en las mÃ©tricas relevantes

Modelos mÃ¡s complejos no garantizaron mejores resultados

El solapamiento entre clases limita el desempeÃ±o mÃ¡ximo alcanzable

El proceso y las decisiones tÃ©cnicas son tan importantes como la mÃ©trica final

#----------------------------------------------------

ğŸ› ï¸ TecnologÃ­as utilizadas

Python

Pandas / NumPy

Scikit-learn

Matplotlib

#-----------------------------------------------------
ğŸ‘¤ Autor

JoaquÃ­n Castro
Estudiante de Ciencia de Datos / Machine Learning


## ğŸ§© Comentario final

Este README:
- no exagera resultados  
- explica decisiones  
- muestra criterio real  
- **queda muy bien para GitHub y LinkedIn**

Cuando quieras, el prÃ³ximo paso puede ser:
- texto corto para LinkedIn
- descripciÃ³n para CV
- o planear el **siguiente proyecto** con otro enfoque

Este proyecto ya estÃ¡ **cerrado como corresponde** ğŸ‘
